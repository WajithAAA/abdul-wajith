{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (2.11.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.30.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: numpy>=1.20 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.24.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: packaging in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: setuptools in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (67.2.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.51.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (23.1.21)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.16.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.12.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in e:\\studies\\projects\\personal-portfolio\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import logging\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    Conv1D,\n",
    "    Dropout,\n",
    "    Input,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import regularizers\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 20\n",
    "batch_size = 16\n",
    "dev_size = 0.1\n",
    "num_class = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-multilingual-cased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Input Sentiment\n",
       "0                            i didnt feel humiliated   sadness\n",
       "1  i can go from feeling so hopeless to so damned...   sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong     anger\n",
       "3  i am ever feeling nostalgic about the fireplac...      love\n",
       "4                               i am feeling grouchy     anger"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(r'dataset\\train.txt', header =None, sep =';', names = ['Input','Sentiment'], encoding='utf-8')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im updating my blog because i feel shitty</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i never make her separate from me because i do...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was feeling a little vain when i did this one</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Input Sentiment\n",
       "0  im feeling rather rotten so im not very ambiti...   sadness\n",
       "1          im updating my blog because i feel shitty   sadness\n",
       "2  i never make her separate from me because i do...   sadness\n",
       "3  i left with my bouquet of red and yellow tulip...       joy\n",
       "4    i was feeling a little vain when i did this one   sadness"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(r'dataset\\test.txt', header = None, sep =';', names = ['Input','Sentiment'],encoding='utf-8')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Sentiment'].replace(\"anger\",0,inplace = True)\n",
    "df_train['Sentiment'].replace(\"fear\",1,inplace = True)\n",
    "df_train['Sentiment'].replace(\"joy\",2,inplace = True)\n",
    "df_train['Sentiment'].replace(\"love\",3,inplace = True)\n",
    "df_train['Sentiment'].replace(\"sadness\",4,inplace = True)\n",
    "df_train['Sentiment'].replace(\"surprise\",5,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Sentiment'].replace(\"anger\",0,inplace = True)\n",
    "df_test['Sentiment'].replace(\"fear\",1,inplace = True)\n",
    "df_test['Sentiment'].replace(\"joy\",2,inplace = True)\n",
    "df_test['Sentiment'].replace(\"love\",3,inplace = True)\n",
    "df_test['Sentiment'].replace(\"sadness\",4,inplace = True)\n",
    "df_test['Sentiment'].replace(\"surprise\",5,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Input        0\n",
       "Sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop_duplicates(inplace=True)\n",
    "df_test.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15999, 2)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train[\"Input\"]\n",
    "y_train = df_train[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_train[\"Input\"]\n",
    "y_test = df_train[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(data):\n",
    "    tokens = tokenizer.batch_encode_plus(\n",
    "        data, max_length=max_length, padding=\"max_length\", truncation=True\n",
    "    )\n",
    "    return tf.constant(tokens[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_encoded = bert_encode(x_train)\n",
    "dev_encoded = bert_encode(x_test)\n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(y_train.values, num_classes=num_class)\n",
    "dev_labels = tf.keras.utils.to_categorical(y_test.values, num_classes=num_class)\n",
    "\n",
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((train_encoded, train_labels))\n",
    "    .shuffle(100)\n",
    "    .batch(batch_size)\n",
    ").cache()\n",
    "\n",
    "dev_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((dev_encoded, dev_labels))\n",
    "    .shuffle(100)\n",
    "    .batch(batch_size)\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_tweets_model():\n",
    "    bert_encoder = TFBertModel.from_pretrained(model_name, output_attentions=True)\n",
    "    input_word_ids = Input(\n",
    "        shape=(max_length,), dtype=tf.int32, name=\"input_ids\"\n",
    "    )\n",
    "    last_hidden_states = bert_encoder(input_word_ids)[0]\n",
    "    clf_output = Flatten()(last_hidden_states)\n",
    "    net = Dense(40, activation=\"relu\")(clf_output)\n",
    "    net = Dropout(0.3)(net)\n",
    "\n",
    "    net = Dense(30, activation=\"relu\")(net)\n",
    "    net = Dropout(0.3)(net)\n",
    "\n",
    "    net = Dense(20, activation=\"relu\")(net)\n",
    "    net = Dropout(0.3)(net)\n",
    "\n",
    "    output = Dense(num_class, activation=\"softmax\")(net)\n",
    "    model = Model(inputs=input_word_ids, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ac0abea8904818a2f780f68577d8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"tf_model.h5\";:   0%|          | 0.00/1.08G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_ids (InputLayer)      [(None, 20)]              0         \n",
      "                                                                 \n",
      " tf_bert_model (TFBertModel)  TFBaseModelOutputWithPoo  177853440\n",
      "                             lingAndCrossAttentions(l            \n",
      "                             ast_hidden_state=(None,             \n",
      "                             20, 768),                           \n",
      "                              pooler_output=(None, 76            \n",
      "                             8),                                 \n",
      "                              past_key_values=None, h            \n",
      "                             idden_states=None, atten            \n",
      "                             tions=((None, 12, None,             \n",
      "                             20),                                \n",
      "                              (None, 12, None, 20),              \n",
      "                              (None, 12, None, 20),              \n",
      "                              (None, 12, None, 20),              \n",
      "                              (None, 12, None, 20),              \n",
      "                              (None, 12, None, 20),              \n",
      "                              (None, 12, None, 20),              \n",
      "                              (None, 12, None, 20),              \n",
      "                              (None, 12, None, 20),              \n",
      "                              (None, 12, None, 20),              \n",
      "                              (None, 12, None, 20),              \n",
      "                              (None, 12, None, 20)),             \n",
      "                              cross_attentions=None)             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 15360)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 40)                614440    \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 40)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 30)                1230      \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 30)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 20)                620       \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 20)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6)                 126       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 178,469,856\n",
      "Trainable params: 178,469,856\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = bert_tweets_model()\n",
    "adam_optimizer = Adam(learning_rate=1e-5)\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", optimizer=adam_optimizer, metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping=tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.0001,\n",
    "    patience=20, \n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    epochs=20,\n",
    "    validation_data=dev_dataset,\n",
    "    verbose=1,\n",
    "    callbacks=early_stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('emotion_model.h5' , overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('emotion_model.h5',custom_objects={\"TFBertModel\": TFBertModel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history[\"val_\" + string])\n",
    "    plt.title('Emotional model')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, \"val_\" + string])\n",
    "    plt.show()\n",
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_csv('dataset/val.txt', header =None, sep =';', names = ['Input','Sentiment'], encoding='utf-8')\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val['Sentiment'].replace(\"anger\",0,inplace = True)\n",
    "val['Sentiment'].replace(\"fear\",1,inplace = True)\n",
    "val['Sentiment'].replace(\"joy\",2,inplace = True)\n",
    "val['Sentiment'].replace(\"love\",3,inplace = True)\n",
    "val['Sentiment'].replace(\"sadness\",4,inplace = True)\n",
    "val['Sentiment'].replace(\"surprise\",5,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = val[\"Input\"]\n",
    "y_val = val[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoded = bert_encode(x_val)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_encoded).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = new_model.predict(test_dataset, batch_size=batch_size)\n",
    "predicted_binary = np.argmax(predicted, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_val,predicted_binary)\n",
    "print('Accuracy: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification report')\n",
    "print(metrics.classification_report(y_val, predicted_binary))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16 (default, Jan 17 2023, 22:25:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba8a02ed82966242d429b8da39cac32d05db4e7021d0a7692a79f8139710cae9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
